{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf \n",
    "import os \n",
    "from databento_dbn import FIXED_PRICE_SCALE, UNDEF_PRICE\n",
    "\n",
    "base_path = os.getcwd()\n",
    "from typing import Literal\n",
    "def build_symbol_df(symbol: Literal['GOOG', 'GOOGL']):\n",
    "    goog_dir = \"processed/GOOG\" if symbol == 'GOOG' else \"processed/GOOGL\"\n",
    "    goog_df_paths = [f\"{base_path}/{goog_dir}/{file}\" for file in os.listdir(f\"{base_path}/{goog_dir}\")]\n",
    "    keep_cols = [\"ts_recv\", 'price']\n",
    "    goog_df = cudf.read_parquet(goog_df_paths[0])\n",
    "    orig_cols = goog_df.columns\n",
    "    goog_df = goog_df.drop(columns=[col for col in goog_df.columns if col not in keep_cols])\n",
    "    for file in goog_df_paths[1:]:\n",
    "        df = cudf.read_parquet(file).drop(columns=[col for col in orig_cols if col not in keep_cols])\n",
    "        goog_df = cudf.concat([goog_df, df])\n",
    "    goog_df = goog_df.sort_values(by='ts_recv')\n",
    "    return goog_df\n",
    "\n",
    "# goog_df = build_symbol_df('GOOG')\n",
    "# googl_df = build_symbol_df('GOOGL')\n",
    "\n",
    "# goog_df['price'] = goog_df['price'] / FIXED_PRICE_SCALE\n",
    "# googl_df['price'] = googl_df['price'] / FIXED_PRICE_SCALE\n",
    "\n",
    "# goog_df.to_parquet(goog_path)\n",
    "# googl_df.to_parquet(googl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(time_unit: str): \n",
    "        \n",
    "    goog_path = f\"{base_path}/GOOG.parquet\"\n",
    "    googl_path = f\"{base_path}/GOOGL.parquet\"\n",
    "    goog_df = cudf.read_parquet(goog_path)\n",
    "    googl_df = cudf.read_parquet(googl_path)\n",
    "\n",
    "    goog_df = goog_df[goog_df['price'] < 500]\n",
    "    googl_df = googl_df[googl_df['price'] < 500]\n",
    "    merged_goog = goog_df\n",
    "    merged_googl = googl_df \n",
    "    merged_goog['ts_recv'] = merged_goog['ts_recv'].astype('datetime64[ms]').dt.floor(time_unit)\n",
    "    merged_goog = merged_goog.groupby('ts_recv').mean()\n",
    "    merged_googl['ts_recv'] = merged_googl['ts_recv'].astype('datetime64[ms]').dt.floor(time_unit)\n",
    "    merged_googl = merged_googl.groupby('ts_recv').mean()\n",
    "\n",
    "    merged_df = cudf.merge(merged_goog, merged_googl, on='ts_recv', how='inner', suffixes=('_goog', '_googl'))\n",
    "    merged_df = merged_df.reset_index()\n",
    "    merged_df = merged_df.sort_values(by='ts_recv')\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time unit: ms\n",
      "0.02332943996730617\n",
      "0.33312774165899783\n",
      "0.01189051853222879\n",
      "0.01189051853222879\n",
      "time unit: ms\n",
      "0.02194541405474677\n",
      "0.2923794160117022\n",
      "0.01068284651761066\n",
      "0.01068284651761066\n",
      "time unit: ms\n",
      "0.02031878822802722\n",
      "0.24461767209971258\n",
      "0.009598129682295172\n",
      "0.009598129682295172\n",
      "time unit: s\n",
      "0.05731241635065476\n",
      "0.479832108754642\n",
      "0.018053828856783565\n",
      "0.018053828856783565\n",
      "time unit: s\n",
      "0.04091184421598063\n",
      "0.42760912395035366\n",
      "0.011022784813658162\n",
      "0.011022784813658162\n",
      "time unit: s\n",
      "0.006352982063794\n",
      "0.3807220503096546\n",
      "0.005803145453220256\n",
      "0.005803145453220256\n",
      "time unit: min\n",
      "0.19735651658637596\n",
      "0.3744441637006528\n",
      "0.08952314624178433\n",
      "0.08952314624178433\n",
      "time unit: min\n",
      "0.12646743402981092\n",
      "0.2704386574781307\n",
      "0.041233922932599795\n",
      "0.041233922932599795\n",
      "time unit: min\n",
      "0.015334875158037454\n",
      "0.11300122467017139\n",
      "0.0010790387342186267\n",
      "0.0010790387342186267\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation between the two prices\n",
    "for time_unit in ['ms', 's', 'min']:\n",
    "    for offset in [5, 10, 30]: \n",
    "        merged_df = merge(time_unit)\n",
    "        print(f\"time unit: {time_unit}\")\n",
    "        print(merged_df['price_goog'].shift(offset).dropna().corr(merged_df['price_googl']))\n",
    "        print(merged_df['price_goog'].shift(offset).dropna().corr(merged_df['price_goog']))\n",
    "\n",
    "        merged_df[\"returns_googl\"] = (merged_df['price_googl'] / merged_df['price_googl'].shift(1))\n",
    "        merged_df[\"returns_goog\"] = (merged_df['price_goog'] / merged_df['price_goog'].shift(1))\n",
    "\n",
    "        print(merged_df[\"returns_googl\"].shift(offset).dropna().corr(merged_df[\"returns_goog\"]))\n",
    "        print(merged_df[\"returns_googl\"].shift(offset).dropna().corr(merged_df[\"returns_goog\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import numpy as np \n",
    "# Function to perform Augmented Dickey-Fuller test\n",
    "def adf_test(series, title=''):\n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    print(f'ADF Statistic for {title}: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value}')\n",
    "\n",
    "# Performing ADF test on both series\n",
    "subsample_percent = 0.05\n",
    "goog_price = merged_df['price_goog'].to_numpy().astype(np.float16)\n",
    "googl_price = merged_df['price_googl'].to_numpy().astype(np.float16)\n",
    "# adf_test(goog_price, title='price_goog')\n",
    "# adf_test(googl_price, title='price_googl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Eigenvalues': array([0.16074036, 0.09819602]),\n",
       " 'Test Statistic': array([9778.90208348, 3627.97282724]),\n",
       " 'Critical Values (90%, 95%, 99%)': array([[13.4294, 15.4943, 19.9349],\n",
       "        [ 2.7055,  3.8415,  6.6349]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Setting up data for Johansen cointegration test\n",
    "data_for_test = merged_df[['price_googl', 'price_goog']].dropna()\n",
    "data_for_test = data_for_test.to_numpy().astype(np.float16)\n",
    "\n",
    "# Perform the Johansen cointegration test\n",
    "# The 'det_order' parameter specifies the deterministic part of the setup; 0 means no deterministic part\n",
    "# The 'k_ar_diff' specifies the lag, here using 1 for simplicity\n",
    "johansen_test = coint_johansen(data_for_test, det_order=0, k_ar_diff=1)\n",
    "\n",
    "# Display the results\n",
    "eig = johansen_test.eig  # Eigenvalues\n",
    "lr1 = johansen_test.lr1  # Test statistic\n",
    "cvt = johansen_test.cvt  # Critical values for the test statistic at the 90%, 95%, 99% confidence levels\n",
    "\n",
    "johansen_results = {\n",
    "    \"Eigenvalues\": eig,\n",
    "    \"Test Statistic\": lr1,\n",
    "    \"Critical Values (90%, 95%, 99%)\": cvt\n",
    "}\n",
    "\n",
    "johansen_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algotrader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
